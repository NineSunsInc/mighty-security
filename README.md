# MCP Security Analyzer ğŸ›¡ï¸

A security analyzer for Model Context Protocol (MCP) tools that detects malicious patterns and potential security threats through static code analysis.

## ğŸš¨ The Problem

MCP tools are becoming critical infrastructure for AI applications, but they present serious security risks:

- **43% of MCP servers have command injection vulnerabilities**
- **30% allow unrestricted URL fetches (SSRF attacks)**
- **22% leak files outside intended directories**
- Recent exploits like the GitHub MCP vulnerability show how prompt injection can leak private data

## âœ… What This Tool Actually Detects

### Current Detection Capabilities (Honest Assessment)

#### 1. **Command Execution Threats** (~40% coverage)
âœ… **Detects Well:**
- `exec()` and `eval()` function calls
- `compile()` usage
- Some AST-based code execution patterns

âŒ **Currently Misses:**
- `os.system()` without specific characters
- `subprocess` calls with `shell=True`
- Indirect execution through variables
- `__import__()` dynamic imports

#### 2. **Credential Theft Patterns** (~15% coverage)
âœ… **Detects Well:**
- Generic "file read + network send" patterns
- Some environment variable access

âŒ **Currently Misses:**
- AWS credentials access via `expanduser()`
- SSH key theft patterns
- Docker/Kubernetes config access
- Browser credential theft
- Keychain/keyring access

#### 3. **Prompt Injection** (~80% coverage)
âœ… **Detects Well:**
- Prompt injection in MCP metadata files
- Common injection patterns in strings
- System tag injections

âŒ **Currently Misses:**
- Sophisticated multi-step injections
- Context-aware injections

#### 4. **Data Exfiltration** (~30% coverage)
âœ… **Detects Well:**
- Basic HTTP POST with data
- Some file-to-network flows

âŒ **Currently Misses:**
- DNS tunneling
- Steganography
- Encrypted channels
- Indirect exfiltration

#### 5. **Code Obfuscation** (~30% coverage)
âœ… **Detects Well:**
- High entropy variable names
- Some suspicious naming patterns

âŒ **Currently Misses:**
- Base64 decode + exec patterns
- Compression-based obfuscation
- Unicode escapes
- Most real-world obfuscation

### Overall Detection Rate: ~40%
- Good at detecting obvious, direct threats
- Poor at detecting sophisticated or indirect attacks
- Many false positives on safe code

## âœ¨ Whatâ€™s new (architecture + early improvements)

Weâ€™ve started a major hardening effort to align with standard static-analysis practices (OWASP/ASVS, CodeQL/Semgrep-style rule packs) and to reduce false positives by backing findings with evidence.

- Orchestrator stays thin; rules and engines live in dedicated modules:
  - `analyzers/security/` for specialized rules (e.g., SSRF, credentials)
  - `analyzers/taint/` for inter-procedural data-flow (sourceâ†’sink) with `FlowTrace`
  - `src/semantics/` for semantic ensemble and LLM coordination
- Immediate, user-visible improvements:
  - Generic secret detection in code and JSON configs (including `mcp.json`): detects private keys, JWTs, common API token formats, and high-entropy strings
  - CWE tagging in findings (e.g., `CWE-918` for SSRF, `CWE-77` for command injection)
- Experimental scaffolding (present, but not fully active yet):
  - SSRF rule hooks on `requests.*` callsites
  - Inter-procedural taint analysis wiring in the deep phase

These experimental modules are stubbed today and wonâ€™t change your results until the rule logic is completed in upcoming commits. Secret detection is active now and will show up when secrets are present.

## ğŸš€ Quick Start

The NextJS Leaderboard and scanning codebase is located [here](https://github.com/olivercarmont/mighty-security-web-app)

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/mcp-security-analyzer.git
cd mcp-security-analyzer

# Python 3.11+

# Option A: uv (recommended)
brew install uv  # macOS
uv sync -p 3.11

# Option B: pip + venv
python3 -m venv .venv
source .venv/bin/activate  # IMPORTANT: Always activate the virtual environment!
pip install -U pip
pip install -e .

# Optional: enable ML features used by src/semantics/*
pip install transformers torch sentence-transformers scikit-learn networkx gitpython

# Optional: enable LLM-powered analysis (Cerebras GPT-OSS-120B)
pip install cerebras-cloud-sdk
# Set your API key in .env file:
echo "CEREBRAS_API_KEY=your_api_key_here" > .env
```

### Basic Usage

âš ï¸ **IMPORTANT**: Always activate the virtual environment before running the analyzer:

```bash
# Activate virtual environment first!
source .venv/bin/activate
```

#### Standard Analysis (Pattern-based + ML)

```bash
# Analyze a GitHub repository
python analyzers/comprehensive_mcp_analyzer.py https://github.com/example/mcp-tool

# Analyze a local directory
python analyzers/comprehensive_mcp_analyzer.py /path/to/mcp/tool

# Analyze current directory
python analyzers/comprehensive_mcp_analyzer.py .
```

#### Enhanced Analysis with LLM (Cerebras GPT-OSS-120B)

The `--llm` flag enables AI-powered deep analysis using Cerebras' 120B parameter model for more sophisticated threat detection:

```bash
# With LLM for enhanced detection (requires CEREBRAS_API_KEY)
python analyzers/comprehensive_mcp_analyzer.py https://github.com/github/github-mcp-server --llm

# Analyze local directory with LLM
python analyzers/comprehensive_mcp_analyzer.py /path/to/mcp/tool --llm

# Example: Analyze the malicious examples with LLM
python analyzers/comprehensive_mcp_analyzer.py examples/malicious_credential_theft --llm
```

**What the --llm flag adds:**
- ğŸ¤– AI-powered code analysis with 64K context window
- ğŸ¯ Better detection of sophisticated attack patterns
- ğŸ“Š Contextual understanding of code intent
- ğŸ” Reduced false positives through semantic analysis
- âš¡ Smart file prioritization for efficient analysis

### Example Output

```
======================================================================
ğŸ”’ MCP SECURITY ANALYZER
======================================================================
Target: https://github.com/example/mcp-tool
Mode: Deep Scan
======================================================================

ğŸ“Š Starting scan of 15 files...
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ” Scanning files
   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘]  90.0% â”‚ 14/15 files â”‚ ETA: 1s

ğŸ“Š OVERALL ASSESSMENT
   Threat Level: HIGH
   Threat Score: 66.00%
   
âš ï¸ THREATS DETECTED: 8

   COMMAND_INJECTION (2 threats)
      â€¢ Direct exec() usage
        File: tool.py, Line: 45
      â€¢ Direct eval() usage  
        File: tool.py, Line: 89

ğŸ’¡ RECOMMENDATIONS:
   âš ï¸ HIGH RISK - Thorough review required
   â€¢ Detected command injection risks
   â€¢ Manual review strongly recommended
```

### Super Evals (stress tests)

Use these curated examples to validate detection:

```bash
# 1) SSRF unguarded (should flag SSRF risks â€“ upcoming rule release)
python analyzers/comprehensive_mcp_analyzer.py examples/super_evals/ssrf_unguarded

# 2) SSRF guarded (should be low/no findings for SSRF)
python analyzers/comprehensive_mcp_analyzer.py examples/super_evals/ssrf_guarded

# 3) Credential exfiltration flow (should flag secret read + network send)
python analyzers/comprehensive_mcp_analyzer.py examples/super_evals/creds_flow

# 4) Indirect command execution (taint will catch in upcoming release)
python analyzers/comprehensive_mcp_analyzer.py examples/super_evals/command_injection

# 5) Secrets in mcp.json (active now: token/private key/JWT detection)
python analyzers/comprehensive_mcp_analyzer.py examples/super_evals/mcp_secrets
```

## â“ Why your report may look unchanged

If you ran something like:

```bash
python analyzers/comprehensive_mcp_analyzer.py ./examples/suspicious_mixed
```

and didnâ€™t see changes, thatâ€™s expected in this snapshot:

- The new SSRF hooks and taint engine are scaffolds and donâ€™t emit new findings yet (rule logic ships next).
- The `suspicious_mixed` example doesnâ€™t contain secrets, so the new secret detector wonâ€™t trigger.

You can validate a visible improvement now by scanning examples that include secrets or credential access:

```bash
# Contains environment/credential access patterns
python analyzers/comprehensive_mcp_analyzer.py ./examples/malicious_credential_theft

# Or any repo with tokens in mcp.json/package.json to see credential findings
```

In the next release, SSRF and taint rules will start emitting findings with evidence-backed flow traces and missing-guard diagnostics.

## âš ï¸ Important Limitations

### What This Tool CANNOT Do:

1. **Runtime Analysis** - Only static code analysis, no dynamic behavior monitoring
2. **Context Awareness** - Cannot distinguish between safe hardcoded values and dangerous user input
3. **Data Flow Tracking** - Limited ability to follow variables through code
4. **Sophisticated Attacks** - Misses most advanced attack patterns
5. **Multi-file Analysis** - Limited cross-file threat detection

### Known False Positives:
- Flags standard library imports as "dangerous"
- Marks common variable names as "suspicious"
- Over-reports on safe operations

### Known False Negatives:
- Misses indirect command execution
- Fails to detect most credential theft
- Cannot detect time bombs or logic bombs
- Misses obfuscated payloads

## ğŸ“Š Scoring System Documentation

### Understanding the Threat Score

The **Threat Score** (0-100%) represents the combined maliciousness rating of the analyzed code. It's calculated using multiple factors:

#### Threat Score Calculation
```
threat_score = weighted_average(
    pattern_threats * 0.35,    # Direct threat patterns found
    data_flows * 0.25,         # Dangerous data flow patterns
    behaviors * 0.20,          # Suspicious behavioral indicators
    ml_score * 0.20            # Machine learning analysis (if enabled)
)
```

#### Risk Levels Based on Threat Score
- **CRITICAL** (â‰¥80%): ğŸ”´ Immediate compromise - Do not use
- **HIGH** (â‰¥60%): ğŸŸ  Significant risk - Extensive review required
- **MEDIUM** (â‰¥40%): ğŸŸ¡ Potential vulnerability - Review before use
- **LOW** (â‰¥20%): ğŸŸ¢ Minor concern - Generally safe with improvements
- **MINIMAL** (<20%): âœ… Safe for use - Standard precautions apply

### Severity Levels Explained

Each individual threat is assigned a severity level:

- **CRITICAL**: ğŸ”´ Immediate security compromise (e.g., direct command execution, credential theft)
- **HIGH**: ğŸŸ  Significant security risk (e.g., unvalidated user input, SSRF vulnerabilities)
- **MEDIUM**: ğŸŸ¡ Potential vulnerability (e.g., obfuscation, suspicious patterns)
- **LOW**: ğŸŸ¢ Minor security concern (e.g., outdated dependencies, code quality issues)
- **INFO**: â„¹ï¸ Informational finding (e.g., best practice recommendations)

### Confidence Level

The **Confidence Level** (0-100%) indicates the analysis coverage and certainty:
- **90-100%**: Complete analysis with high certainty
- **70-89%**: Good coverage with reliable results
- **50-69%**: Moderate coverage, some uncertainty
- **<50%**: Limited analysis, results may be incomplete

### Attack Vector Categories

Threats are categorized by attack vector:
- **COMMAND_INJECTION**: Code execution vulnerabilities
- **DATA_EXFILTRATION**: Unauthorized data transmission
- **CREDENTIAL_THEFT**: Attempts to steal secrets/credentials
- **OBFUSCATION**: Hidden or encoded malicious code
- **PROMPT_INJECTION**: LLM manipulation attempts
- **NETWORK_BACKDOOR**: Remote access mechanisms
- **PERSISTENCE**: Backdoor installation attempts

## ğŸ” How It Works

1. **Static Pattern Matching**: Uses regex patterns to find dangerous code
2. **AST Analysis**: Basic Python AST parsing for some patterns
3. **Entropy Analysis**: Detects high-entropy (obfuscated) code
4. **File Fingerprinting**: SHA-512/SHA3-512 hashes for integrity
5. **Weighted Threat Scoring**: Combines multiple signals into a unified score
6. **Optional Semantic Ensemble**: If ML dependencies are installed, runs `src/semantics.ModelEnsemble` to compute an ML maliciousness score used in the final assessment (the CLI prints "ML Score"). Falls back to a lightweight local heuristic otherwise.
7. **LLM Integration (--llm flag)**: When enabled with Cerebras API key, uses GPT-OSS-120B for deep semantic analysis, providing contextual threat detection beyond pattern matching

### Whatâ€™s different now under the hood
- The orchestrator wires in:
  - Secret detection (active)
  - SSRF rule hook (scaffolded)
  - Taint engine (scaffolded) â†’ converts `FlowTrace` to `DataFlow` + `ThreatIndicator`
- Findings can include `cwe_ids` and structured evidence (e.g., missing SSRF guards, snippet previews, flow paths).

## ğŸ¯ Real-World Performance

| Attack Type | Detection Rate | Notes |
|-------------|---------------|-------|
| **Direct exec/eval** | âœ… 90% | Good detection |
| **os.system** | âŒ 10% | Poor - pattern too specific |
| **Credential Theft** | âŒ 15% | Very limited |
| **Prompt Injection** | âœ… 80% | Works well for metadata |
| **Obfuscation** | âš ï¸ 30% | Basic detection only |
| **Network Backdoors** | âš ï¸ 20% | Limited patterns |
| **RADE Attacks** | âŒ 5% | Almost no detection |
| **Tool Poisoning** | âŒ 10% | Minimal coverage |

## ğŸ› ï¸ Technical Details

### File Structure & Purpose

```
analyzers/
â”œâ”€â”€ comprehensive_mcp_analyzer.py  # Main analyzer (use this)
â”‚   # Entry point for all security scans. Orchestrates pattern matching,
â”‚   # ML analysis, and report generation. Handles both local and GitHub repos.
â”‚
â”œâ”€â”€ report_formatter.py            # Comprehensive report generation
â”‚   # Formats analysis results into readable reports with risk matrices,
â”‚   # threat breakdowns, and actionable recommendations.
â”‚
â”œâ”€â”€ shared_constants.py            # Reusable patterns and constants
â”‚   # Contains all threat detection patterns, regex rules, and
â”‚   # severity mappings used across the analyzer.
â”‚
â”œâ”€â”€ security/                      # Specialized security modules
â”‚   â”œâ”€â”€ ssrf_detector.py          # SSRF vulnerability detection
â”‚   â””â”€â”€ credential_scanner.py     # Secret/credential detection
â”‚
â”œâ”€â”€ taint/                         # Data flow analysis
â”‚   â””â”€â”€ taint_analyzer.py         # Tracks data from source to sink
â”‚
â”œâ”€â”€ llm/                           # LLM integration (--llm flag)
â”‚   â”œâ”€â”€ cerebras_analyzer.py      # Cerebras GPT-OSS-120B integration
â”‚   â”‚   # Interfaces with Cerebras API for deep semantic analysis
â”‚   â”‚
â”‚   â”œâ”€â”€ context_optimizer.py      # Smart file ranking for LLM
â”‚   â”‚   # Prioritizes files for analysis within LLM context limits
â”‚   â”‚
â”‚   â”œâ”€â”€ llm_integration.py        # Coordinates LLM analysis
â”‚   â”‚   # Manages batch processing and result aggregation
â”‚   â”‚
â”‚   â””â”€â”€ prompts.py                # Security-focused prompts
â”‚       # Contains specialized prompts for threat detection
â”‚
â””â”€â”€ archive/                       # Old/experimental analyzers
    # Legacy code and experimental features not in production

src/
â”œâ”€â”€ semantics/                     # ML-based analysis
â”‚   â”œâ”€â”€ model_ensemble.py         # Ensemble ML models for threat detection
â”‚   â”œâ”€â”€ semantic_analyzer.py      # Code semantic understanding
â”‚   â””â”€â”€ pattern_learner.py        # Pattern learning from examples
â”‚
â””â”€â”€ utils/                         # Utility functions
    â”œâ”€â”€ file_processor.py          # File handling and parsing
    â”œâ”€â”€ git_handler.py             # GitHub repository cloning
    â””â”€â”€ report_generator.py        # Report formatting utilities

examples/
â”œâ”€â”€ malicious_command_injection/    # Test cases for command injection
â”œâ”€â”€ malicious_credential_theft/     # Credential theft examples
â”œâ”€â”€ malicious_obfuscated/          # Obfuscated code samples
â”œâ”€â”€ malicious_prompt_injection/     # Prompt injection tests
â”œâ”€â”€ suspicious_mixed/               # Mixed threat examples
â””â”€â”€ super_evals/                   # Comprehensive test suite
    â”œâ”€â”€ ssrf_unguarded/            # SSRF without protection
    â”œâ”€â”€ ssrf_guarded/              # SSRF with proper guards
    â”œâ”€â”€ creds_flow/                # Credential flow tracking
    â”œâ”€â”€ command_injection/         # Various injection patterns
    â””â”€â”€ mcp_secrets/               # Secrets in config files

reports/                           # Generated security reports
    # JSON and text reports from analysis runs

docs/                              # Documentation
    # Additional documentation and guides
```

### Key Files Explained

#### Core Analysis Engine
- **comprehensive_mcp_analyzer.py**: The main orchestrator that coordinates all analysis modules, manages the scanning pipeline, and generates final threat scores.

#### Detection Modules
- **shared_constants.py**: Central repository of threat patterns, including regex for command injection, data exfiltration patterns, and suspicious API calls.
- **ssrf_detector.py**: Identifies Server-Side Request Forgery vulnerabilities by analyzing HTTP request patterns and URL validation.
- **credential_scanner.py**: Detects hardcoded credentials, API keys, and sensitive data patterns in code and configuration files.

#### Analysis Enhancement
- **taint_analyzer.py**: Performs inter-procedural data flow analysis to track how user input flows to dangerous sinks.
- **model_ensemble.py**: Combines multiple ML models to provide a consensus threat score with reduced false positives.

#### Reporting
- **report_formatter.py**: Transforms raw analysis data into comprehensive, actionable security reports with severity ratings and remediation guidance.

### Threat Categories Checked
- **COMMAND_INJECTION**: exec, eval, compile
- **CREDENTIAL_THEFT**: File access patterns
- **DATA_EXFILTRATION**: Network operations
- **PROMPT_INJECTION**: LLM manipulation
- **OBFUSCATION**: Hidden/encoded threats
- **PERSISTENCE**: Backdoor mechanisms
- **NETWORK_BACKDOOR**: Remote access

## ğŸ”® Roadmap

### Immediate Fixes Needed
- Fix overly specific regex patterns
- Add proper data flow analysis
- Implement context-aware detection
- Reduce false positive rate

### Near-term milestones (actively in progress)
- Implement SSRF guard checks (host/IP validation, redirect policy, `file://` ban) â†’ emit `CWE-918`
- Implement credential rules for common secret stores and sensitive paths â†’ pair with network sinks for CRITICAL
- Inter-procedural taint flows for user_inputâ†’exec and sensitive_readâ†’network, producing path evidence

### Future Improvements
- Add machine learning models (currently claimed but not implemented)
- Implement runtime monitoring
- Add multi-language support beyond Python
- Create CI/CD integration

## âš¡ Performance

- **Scan Speed**: ~100-200 files/second
- **Memory Usage**: <100MB for most repos
- **Accuracy**: ~40% detection rate (needs improvement)
- **False Positive Rate**: ~20-30% (too high)

## ğŸ¤ Contributing

This tool needs significant improvements. Key areas:

1. **Fix Pattern Detection**: Current patterns miss obvious threats
2. **Add Data Flow Analysis**: Track variables from source to sink
3. **Reduce False Positives**: Better discrimination needed
4. **Add Test Coverage**: More comprehensive test cases
5. **Improve Documentation**: Better threat descriptions

See [DETECTION_GAP_ANALYSIS.md](DETECTION_GAP_ANALYSIS.md) for detailed analysis of current gaps. For contribution workflow, see `CONTRIBUTION.md`.

## ğŸ“š References

- [Invariant Labs - GitHub MCP Vulnerability](https://invariantlabs.ai/blog/mcp-github-vulnerability)
- [Docker - MCP Security Issues](https://www.docker.com/blog/mcp-security-issues-threatening-ai-infrastructure/)
- [PromptHub - MCP Security in 2025](https://www.prompthub.us/blog/mcp-security-in-2025)

## âš–ï¸ License

MIT License - See LICENSE file for details

## âš ï¸ Disclaimer

**This tool provides basic security scanning but should NOT be your only security measure.** 

Current limitations:
- Only ~40% detection rate for real threats
- High false positive rate
- Misses many sophisticated attacks
- No runtime protection

Always:
- Manually review MCP tools before use
- Use multiple security layers
- Run tools in sandboxed environments
- Monitor runtime behavior

## ğŸ“ Support

For questions or security concerns:
- Open an issue on GitHub

---

**Remember**: This tool is a work in progress with significant detection gaps. Do not rely on it as your sole security measure. Always perform manual security reviews and use defense-in-depth strategies.