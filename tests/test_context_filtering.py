#!/usr/bin/env python3
"""
Comprehensive test suite for context-aware filtering and threat detection.
Tests that real vulnerabilities are still caught while reducing false positives.
"""

import sys
from pathlib import Path

# Add parent to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.analyzers.context_analyzer import ContextAnalyzer
from src.analyzers.smart_filter import SmartFilter


class TestContextAwareFiltering:
    """Test suite for context-aware security scanning"""

    def __init__(self):
        self.passed = 0
        self.failed = 0
        self.results = []

    def assert_equal(self, actual, expected, message):
        """Assert helper with tracking"""
        if actual == expected:
            self.passed += 1
            self.results.append(f"✅ PASS: {message}")
            return True
        else:
            self.failed += 1
            self.results.append(f"❌ FAIL: {message}")
            self.results.append(f"    Expected: {expected}, Got: {actual}")
            return False

    def test_context_detection(self):
        """Test accurate context detection for various file types"""
        print("\n🔍 Testing Context Detection")
        print("-" * 60)

        analyzer = ContextAnalyzer()

        # Test cases with file path and content
        test_cases = [
            # Test files should be detected
            {
                'path': 'tests/test_security.py',
                'content': 'import unittest\nclass TestSecurity(unittest.TestCase):\n    pass',
                'expected_is_test': True,
                'expected_is_example': False,
                'expected_is_security_tool': False,
                'description': 'Unit test file'
            },
            # Example files should be detected
            {
                'path': 'examples/command_injection/exploit.py',
                'content': '# Example of command injection\nimport os\nos.system(user_input)',
                'expected_is_test': False,
                'expected_is_example': True,
                'expected_is_security_tool': False,
                'description': 'Example exploit code'
            },
            # Security tools should be detected
            {
                'path': 'src/analyzers/vulnerability_scanner.py',
                'content': 'import ast\nclass VulnerabilityScanner:\n    def detect_injection(self): pass',
                'expected_is_test': False,
                'expected_is_example': False,
                'expected_is_security_tool': True,
                'description': 'Security scanner tool'
            },
            # Production code should not match any special context
            {
                'path': 'src/payment_processor.py',
                'content': 'class PaymentProcessor:\n    def process(self, amount): pass',
                'expected_is_test': False,
                'expected_is_example': False,
                'expected_is_security_tool': False,
                'description': 'Production payment code'
            },
            # Test file by content even without test path
            {
                'path': 'src/validation.py',
                'content': 'import pytest\n@pytest.fixture\ndef setup(): pass',
                'expected_is_test': True,
                'expected_is_example': False,
                'expected_is_security_tool': False,
                'description': 'Pytest file detected by content'
            },
            # Generated code detection
            {
                'path': 'src/proto/service_pb2.py',
                'content': '# Generated by protoc\n# DO NOT EDIT',
                'expected_is_test': False,
                'expected_is_example': False,
                'expected_is_security_tool': False,
                'description': 'Generated protobuf file'
            }
        ]

        for case in test_cases:
            context = analyzer.get_file_context(case['path'], case['content'])

            self.assert_equal(
                context.is_test,
                case['expected_is_test'],
                f"{case['description']}: is_test detection"
            )
            self.assert_equal(
                context.is_example,
                case['expected_is_example'],
                f"{case['description']}: is_example detection"
            )
            self.assert_equal(
                context.is_security_tool,
                case['expected_is_security_tool'],
                f"{case['description']}: is_security_tool detection"
            )

    def test_file_filtering(self):
        """Test that files are correctly included/excluded based on profile"""
        print("\n📁 Testing File Filtering")
        print("-" * 60)

        test_paths = [
            ('tests/test_injection.py', 'production', False, 'Test file in production'),
            ('tests/test_injection.py', 'development', True, 'Test file in development'),
            ('examples/demo.py', 'production', False, 'Example in production'),
            ('examples/demo.py', 'development', True, 'Example in development'),
            ('src/main.py', 'production', True, 'Source in production'),
            ('src/main.py', 'development', True, 'Source in development'),
            ('__pycache__/compiled.pyc', 'production', False, 'Cache in production'),
            ('__pycache__/compiled.pyc', 'development', False, 'Cache in development'),
            ('venv/lib/package.py', 'production', False, 'Venv in production'),
            ('.git/config', 'production', False, 'Git in production'),
            ('build/output.js', 'production', False, 'Build dir in production'),
        ]

        for path, profile, should_scan, description in test_paths:
            filter = SmartFilter(profile=profile)
            result = filter.should_scan_file(path)
            self.assert_equal(
                result.should_scan,
                should_scan,
                f"{description}: {path} with {profile} profile"
            )

    def test_threat_severity_adjustment(self):
        """Test that threat severity is correctly adjusted based on context"""
        print("\n⚠️ Testing Threat Severity Adjustment")
        print("-" * 60)

        filter_prod = SmartFilter(profile='production')
        filter_dev = SmartFilter(profile='development')

        # Critical vulnerability in test file
        test_threat = {
            'attack_vector': 'COMMAND_INJECTION',
            'severity': 'CRITICAL',
            'description': 'exec() with user input',
            'file_path': 'tests/test_exploit.py',
            'line_numbers': [42],
            'confidence': 0.95
        }

        # Should be ignored in production
        prod_filtered = filter_prod.filter_threats([test_threat], 'tests/test_exploit.py')
        self.assert_equal(
            len(prod_filtered),
            0,
            "Critical threat in test file ignored in production"
        )

        # Should be downgraded in development
        dev_filtered = filter_dev.filter_threats([test_threat], 'tests/test_exploit.py')
        if dev_filtered:
            self.assert_equal(
                dev_filtered[0]['severity'],
                'HIGH',  # CRITICAL -> HIGH in development for test files
                "Critical threat in test file downgraded in development"
            )

        # Critical vulnerability in production code - should NOT be adjusted
        prod_threat = {
            'attack_vector': 'COMMAND_INJECTION',
            'severity': 'CRITICAL',
            'description': 'exec() with user input',
            'file_path': 'src/api_handler.py',
            'line_numbers': [100],
            'confidence': 0.95
        }

        prod_filtered = filter_prod.filter_threats([prod_threat], 'src/api_handler.py')
        self.assert_equal(
            len(prod_filtered),
            1,
            "Critical threat in production code NOT filtered"
        )
        self.assert_equal(
            prod_filtered[0]['severity'],
            'CRITICAL',
            "Critical threat in production code NOT downgraded"
        )

        # Medium obfuscation in security tool - should be downgraded
        security_threat = {
            'attack_vector': 'OBFUSCATION',
            'severity': 'MEDIUM',
            'description': 'Suspicious variable names: analyzer',
            'file_path': 'src/security_analyzer.py',
            'line_numbers': [50],
            'confidence': 0.7
        }

        # Get context for security tool
        analyzer = ContextAnalyzer()
        security_content = 'import ast\nclass SecurityAnalyzer:\n    def analyze_threats(self): pass'
        context = analyzer.get_file_context('src/security_analyzer.py', security_content)

        # Manually set as security tool for this test
        context.is_security_tool = True
        adjusted = filter_prod.adjust_threat_severity(security_threat.copy(), context)

        # In production profile, security tool patterns may be downgraded
        if context.is_security_tool and 'variable' in security_threat['description']:
            expected_severity = 'LOW'  # Based on config
        else:
            expected_severity = 'MEDIUM'

        self.assert_equal(
            adjusted.get('severity', 'MEDIUM'),
            expected_severity,
            "Obfuscation in security tool appropriately handled"
        )

    def test_real_vulnerabilities_detected(self):
        """Ensure REAL vulnerabilities are still detected in production code"""
        print("\n🚨 Testing Real Vulnerability Detection")
        print("-" * 60)

        filter = SmartFilter(profile='production')

        # Real critical vulnerabilities that should NEVER be filtered
        critical_threats = [
            {
                'attack_vector': 'COMMAND_INJECTION',
                'severity': 'CRITICAL',
                'description': 'subprocess.call with shell=True and user input',
                'file_path': 'src/file_processor.py',
                'line_numbers': [234],
                'confidence': 0.95
            },
            {
                'attack_vector': 'CREDENTIAL_THEFT',
                'severity': 'CRITICAL',
                'description': 'AWS credentials exposed',
                'file_path': 'src/config.py',
                'line_numbers': [45],
                'confidence': 0.9
            },
            {
                'attack_vector': 'SQL_INJECTION',
                'severity': 'CRITICAL',
                'description': 'SQL query with string concatenation',
                'file_path': 'src/database.py',
                'line_numbers': [123],
                'confidence': 0.92
            },
            {
                'attack_vector': 'PATH_TRAVERSAL',
                'severity': 'HIGH',
                'description': 'File path from user input without validation',
                'file_path': 'src/file_handler.py',
                'line_numbers': [67],
                'confidence': 0.88
            }
        ]

        for threat in critical_threats:
            filtered = filter.filter_threats([threat], threat['file_path'])

            self.assert_equal(
                len(filtered),
                1,
                f"Critical vulnerability NOT filtered: {threat['attack_vector']}"
            )

            if filtered:
                self.assert_equal(
                    filtered[0]['severity'],
                    threat['severity'],
                    f"Critical vulnerability severity preserved: {threat['attack_vector']}"
                )

    def test_profile_configuration(self):
        """Test that profiles are correctly loaded and applied"""
        print("\n⚙️ Testing Profile Configuration")
        print("-" * 60)

        profiles = ['production', 'development', 'security-tool']

        for profile_name in profiles:
            filter = SmartFilter(profile=profile_name)
            profile_info = filter.get_profile_info()

            self.assert_equal(
                profile_info['name'],
                profile_name,
                f"Profile {profile_name} loaded correctly"
            )

            # Check that each profile has expected configuration
            has_excludes = profile_info.get('exclude_count', 0) > 0
            self.assert_equal(
                has_excludes,
                True,
                f"Profile {profile_name} has exclusion rules"
            )

    def test_statistics_tracking(self):
        """Test that filtering statistics are correctly tracked"""
        print("\n📊 Testing Statistics Tracking")
        print("-" * 60)

        filter = SmartFilter(profile='production')

        # Process some files
        test_files = [
            'tests/test1.py',
            'tests/test2.py',
            'src/main.py',
            'src/api.py',
            'examples/demo.py'
        ]

        for file_path in test_files:
            filter.should_scan_file(file_path)

        stats = filter.get_stats()

        # In production: tests and examples excluded (3), src included (2)
        self.assert_equal(
            stats['files_excluded'],
            3,
            "Correct number of files excluded"
        )
        self.assert_equal(
            stats['files_included'],
            2,
            "Correct number of files included"
        )

    def run_all_tests(self):
        """Run all test methods"""
        print("\n" + "=" * 70)
        print("COMPREHENSIVE CONTEXT-AWARE FILTERING TEST SUITE")
        print("=" * 70)

        # Run each test method
        self.test_context_detection()
        self.test_file_filtering()
        self.test_threat_severity_adjustment()
        self.test_real_vulnerabilities_detected()
        self.test_profile_configuration()
        self.test_statistics_tracking()

        # Print summary
        print("\n" + "=" * 70)
        print("TEST RESULTS SUMMARY")
        print("=" * 70)
        print(f"\n✅ Passed: {self.passed}")
        print(f"❌ Failed: {self.failed}")
        print(f"📊 Total:  {self.passed + self.failed}")

        if self.failed > 0:
            print("\n⚠️ FAILED TESTS:")
            for result in self.results:
                if result.startswith("❌"):
                    print(result)

        success_rate = (self.passed / (self.passed + self.failed)) * 100 if (self.passed + self.failed) > 0 else 0
        print(f"\n🎯 Success Rate: {success_rate:.1f}%")

        return self.failed == 0


if __name__ == "__main__":
    tester = TestContextAwareFiltering()
    success = tester.run_all_tests()

    if success:
        print("\n✅ ALL TESTS PASSED!")
        sys.exit(0)
    else:
        print("\n❌ SOME TESTS FAILED!")
        sys.exit(1)
